{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce497d-f4af-41a9-a5d6-7ee78ad88500",
   "metadata": {},
   "source": [
    "# 1. Cel / Zakres\n",
    "    - Metody zespołowe\n",
    "        - równoległe\n",
    "        - sekwencyjne\n",
    "    - Hard / soft voting\n",
    "    - Bagging\n",
    "    - Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522788e-11a0-41f2-a2c1-7ae226d841f1",
   "metadata": {},
   "source": [
    "# 2. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9adca48-7512-40a4-9fdb-bf124724aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c4070-ba9b-4ad5-8891-e93f3e35e2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Ćwiczenie:\n",
    "    - Uwaga: stosuj domyślne wartości parametrów dla użytych klas,\n",
    "      chyba, że z opisu danego ćwiczenia wynika inaczej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f7df4-3f9b-46ed-af08-46af71e88225",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Podział Zbioru\n",
    "Podziel zbiór data_breast_cancer na uczący i testujący w proporcjach 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d191c0d-c27c-4188-80a6-275d261fdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer = data_breast_cancer.data\n",
    "y_cancer = data_breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0d990d73-e0bb-4939-bcae-cf2409376fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Zbuduj ensemble\n",
    "Używając klasyfikatorów binarnych, których używałeś(aś) w poprzednich\n",
    "ćwiczeniach, tj.:\n",
    "\n",
    "    - drzewa decyzyjne,\n",
    "    - regresja logistyczna,\n",
    "    - k najbliższych sąsiadów,\n",
    "do klasyfikacji w oparciu o cechy:\n",
    "\n",
    "    - mean texture,\n",
    "    - mean symmetry.\n",
    "Użyj domyślnych parametrów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_cancer_train_texture_symmetry = X_cancer_train[[\"mean texture\", \"mean symmetry\"]]\n",
    "X_cancer_test_texture_symmetry = X_cancer_test[[\"mean texture\", \"mean symmetry\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=3)\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\")\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf_soft = VotingClassifier(\n",
    "        estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='soft'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8aee72ab-c736-4380-92cf-73686946d178",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Porównaj dokładność (accuracy)\n",
    "ww. klasyfikatorów z zespołem z głosowaniem typu:\n",
    "    \n",
    "    - hard\n",
    "    - soft."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('lr', LogisticRegression()),\n                             ('tr', DecisionTreeClassifier(max_depth=3)),\n                             ('knn', KNeighborsClassifier())],\n                 voting='soft')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "log_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "knn_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_hard.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_soft.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_train_tree_pred = tree_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_log_pred = log_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_knn_pred = knn_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vh_pred = voting_clf_hard.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vs_pred = voting_clf_soft.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "acc_tree_train = accuracy_score(y_cancer_train, y_train_tree_pred)\n",
    "acc_log_train = accuracy_score(y_cancer_train, y_train_log_pred)\n",
    "acc_knn_train = accuracy_score(y_cancer_train, y_train_knn_pred)\n",
    "acc_vh_train = accuracy_score(y_cancer_train, y_train_vh_pred)\n",
    "acc_vs_train = accuracy_score(y_cancer_train, y_train_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7692307692307693, 0.7230769230769231, 0.7714285714285715, 0.7802197802197802, 0.789010989010989]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_train, acc_log_train, acc_knn_train, acc_vh_train, acc_vs_train])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "y_test_tree_pred = tree_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_log_pred = log_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_knn_pred = knn_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vh_pred = voting_clf_hard.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vs_pred = voting_clf_soft.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "acc_tree_test = accuracy_score(y_cancer_test, y_test_tree_pred)\n",
    "acc_log_test = accuracy_score(y_cancer_test, y_test_log_pred)\n",
    "acc_knn_test = accuracy_score(y_cancer_test, y_test_knn_pred)\n",
    "acc_vh_test = accuracy_score(y_cancer_test, y_test_vh_pred)\n",
    "acc_vs_test = accuracy_score(y_cancer_test, y_test_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7368421052631579, 0.7017543859649122, 0.6403508771929824, 0.6754385964912281, 0.7456140350877193]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_test, acc_log_test, acc_knn_test, acc_vh_test, acc_vs_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "106bb175-57a5-4767-8d81-da0dc49cf5e2",
   "metadata": {},
   "source": [
    "#### 4. Zapisz rezultaty jako listę par\n",
    "    - (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z w/w klasyfikatorów i umieść ją w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_vote.pkl (razem 5 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - vote.pkl (5 obiektów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "accuracy =[(acc_tree_train, acc_tree_test),\n",
    "           (acc_log_train, acc_log_test),\n",
    "           (acc_knn_train, acc_log_test),\n",
    "           (acc_vh_train, acc_vh_test),\n",
    "           (acc_vs_train, acc_vs_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "clf = [tree_clf, log_clf, knn_clf, voting_clf_hard, voting_clf_soft]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3ca83de0-33a0-4542-b17a-555493c9eb7a",
   "metadata": {},
   "source": [
    "#### 5. Wykonaj na zbiorze uczącym \n",
    "    - wykorzystując 30 drzew decyzyjnych:\n",
    "- Bagging,\n",
    "- Bagging z wykorzystaniem 50% instancji,\n",
    "- Pasting,\n",
    "- Pasting z wykorzystaniem 50% instancji, oraz\n",
    "- Random Forest,\n",
    "- AdaBoost,\n",
    "- Gradient Boosting.\n",
    "\n",
    "###### - Dlaczego Random Forest daje inne rezultaty niż Bagging + drzewa decyzyjne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9d585e-80e6-4275-94c8-0fa44c33f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=True)\n",
    "\n",
    "bag_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                                 max_samples=0.5, bootstrap=True)\n",
    "\n",
    "pas_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=False)\n",
    "\n",
    "pas_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=False)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=30)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "bag_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "rnd_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "ada_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "gb_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e9cdd9ea-7af6-4b94-b702-3151312191d2",
   "metadata": {},
   "source": [
    "#### 6. Oblicz dokładności oraz zapisz je jako listę par\n",
    "    -  (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z ww. estymatorów w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_bag.pkl (razem 7 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - bag.pkl (razem 7 elementów)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "y_train_b_pred = bag_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_bh_pred = bag_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_p_pred = pas_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_ph_pred = pas_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_r_pred = rnd_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_a_pred = ada_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_g_pred = gb_clf.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "acc_bag_train = accuracy_score(y_cancer_train, y_train_b_pred)\n",
    "acc_bagh_train = accuracy_score(y_cancer_train, y_train_bh_pred)\n",
    "acc_pas_train = accuracy_score(y_cancer_train, y_train_p_pred)\n",
    "acc_pash_train = accuracy_score(y_cancer_train, y_train_ph_pred)\n",
    "acc_rnd_train = accuracy_score(y_cancer_train, y_train_r_pred)\n",
    "acc_ada_train = accuracy_score(y_cancer_train, y_train_a_pred)\n",
    "acc_gb_train = accuracy_score(y_cancer_train, y_train_g_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "y_test_b_pred = bag_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_bh_pred = bag_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_p_pred = pas_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_ph_pred = pas_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_r_pred = rnd_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_a_pred = ada_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_g_pred = gb_clf.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a6e5964-eee4-410c-ae5e-661588c7eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_bag_test = accuracy_score(y_cancer_test, y_test_b_pred)\n",
    "acc_bagh_test = accuracy_score(y_cancer_test, y_test_bh_pred)\n",
    "acc_pas_test = accuracy_score(y_cancer_test, y_test_p_pred)\n",
    "acc_pash_test = accuracy_score(y_cancer_test, y_test_ph_pred)\n",
    "acc_rnd_test = accuracy_score(y_cancer_test, y_test_r_pred)\n",
    "acc_ada_test = accuracy_score(y_cancer_test, y_test_a_pred)\n",
    "acc_gb_test = accuracy_score(y_cancer_test, y_test_g_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "acc_bag = [(acc_bag_train, acc_bag_test),\n",
    "       (acc_bagh_train, acc_bagh_test),\n",
    "       (acc_pas_train, acc_pas_test),\n",
    "       (acc_pash_train, acc_pash_test),\n",
    "       (acc_rnd_train, acc_rnd_test),\n",
    "       (acc_ada_train, acc_ada_test),\n",
    "       (acc_gb_train, acc_gb_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1.0, 0.6578947368421053),\n (0.9164835164835164, 0.6842105263157895),\n (1.0, 0.6228070175438597),\n (0.9714285714285714, 0.6842105263157895),\n (1.0, 0.7192982456140351),\n (0.8, 0.7368421052631579),\n (0.8373626373626374, 0.7105263157894737)]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_bag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open('acc_bag.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "bag = [bag_clf, bag_clf_half, pas_clf, pas_clf_half, rnd_clf, ada_clf, gb_clf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "10589a5a-b83b-4654-bb92-ac8d47bbcee9",
   "metadata": {},
   "source": [
    "#### 7. Przeprowadź sampling 2 cech z wszystkich dostepnych\n",
    "    - bez powtórzeń cech z wykorzystaniem 30 drzew decyzyjnych,\n",
    "    - wybierz połowę instancji dla każdego z drzew z powtórzeniami.\n",
    "    \n",
    "###### Notatka:\n",
    "###### Odnosnie zad 7: Tutaj BaggingClassifier z decision tree i max_features=2, Reszta ustawien domyslna trzeba uzyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "bag_clf_s = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=True, max_features=2, bootstrap_features=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n                  max_samples=0.5, n_estimators=30)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf_s.fit(X_cancer_train, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "y_train_bs_pred = bag_clf_s.predict(X_cancer_train)\n",
    "y_test_bs_pred = bag_clf_s.predict(X_cancer_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "acc_bag_s_train = accuracy_score(y_cancer_train, y_train_bs_pred)\n",
    "acc_bag_s_test = accuracy_score(y_cancer_test, y_test_bs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Zapisz dokładności ww estymatora jako listę :\n",
    "    - dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego\n",
    "w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_fea.pkl.\n",
    "Zapisz klasyfikator jako jednoelementową listę w pliku Pickle o nazwie:\n",
    "\n",
    "    - fea.pkl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3526af87-c2b4-48e7-8d61-ddbe7a9cd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fea = [acc_bag_s_train, acc_bag_s_test]\n",
    "\n",
    "with open('acc_fea.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "fea = [bag_clf_s]\n",
    "\n",
    "with open('fea.pkl', 'wb') as f:\n",
    "    pickle.dump(fea, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2bfb34d1-ef87-44c3-b9fd-72976f174a71",
   "metadata": {},
   "source": [
    "#### 9. Sprawdź, które cechy dają najwięszą dokładność.\n",
    "Dostęp do poszczególnych estymatorów, aby obliczyć dokładność,\n",
    "możesz uzyskać za pmocą:\n",
    "    \n",
    "    - BaggingClasifier.estimators_.\n",
    "Cechy wybrane przez sampling dla każdego z estymatorów znajdziesz w:\n",
    "    \n",
    "    - BaggingClassifier.estimators_features_.\n",
    "    \n",
    "Zbuduj ranking estymatorów jako DataFrame, który będzie mieć w kolejnych kolumnach:\n",
    "    \n",
    "    - dokładność dla zb. uczącego,\n",
    "    - dokładnośc dla zb. testującego,\n",
    "    - lista nazw cech.\n",
    "    \n",
    "    - Każdy wiersz to informacje o jednym estymatorze.\n",
    "    - DataFrame posortuj malejąco po dokładności dla zbioru testującego i uczącego\n",
    "\n",
    "Zapisz w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_fea_rank.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dded99e7-ac9d-42e3-915c-f0a14f9afd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for estimator_, estimator_features_ in zip(bag_clf_s.estimators_, bag_clf_s.estimators_features_):\n",
    "    y_train_fea_pred = estimator_.predict(X_cancer_train.iloc[:, estimator_features_])\n",
    "    y_test_fea_pred = estimator_.predict(X_cancer_test.iloc[:, estimator_features_])\n",
    "\n",
    "    acc_fea_train = accuracy_score(y_cancer_train, y_train_fea_pred)\n",
    "    acc_fea_test = accuracy_score(y_cancer_test, y_test_fea_pred)\n",
    "\n",
    "    rank = [acc_fea_train, acc_fea_test, list(X_cancer.columns[estimator_features_])]\n",
    "\n",
    "    fea_rank.append(rank)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "acc_fea_rank = pd.DataFrame(fea_rank, columns=[\"accuracy train\", \"accuracy test\", \"features\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "acc_fea_rank.sort_values(by=[\"accuracy test\", \"accuracy train\"], ascending=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "    accuracy train  accuracy test  \\\n20        0.925275       0.929825   \n0         0.942857       0.903509   \n22        0.934066       0.903509   \n6         0.916484       0.894737   \n27        0.931868       0.885965   \n29        0.929670       0.877193   \n5         0.927473       0.868421   \n1         0.905495       0.850877   \n19        0.938462       0.842105   \n24        0.903297       0.842105   \n3         0.896703       0.833333   \n12        0.841758       0.833333   \n11        0.894505       0.824561   \n14        0.909890       0.798246   \n23        0.841758       0.789474   \n26        0.892308       0.780702   \n16        0.868132       0.780702   \n15        0.881319       0.771930   \n9         0.852747       0.771930   \n28        0.868132       0.754386   \n18        0.865934       0.754386   \n4         0.817582       0.754386   \n25        0.824176       0.728070   \n10        0.778022       0.701754   \n21        0.813187       0.675439   \n7         0.786813       0.675439   \n13        0.804396       0.657895   \n2         0.778022       0.631579   \n8         0.784615       0.561404   \n17        0.734066       0.491228   \n\n                                             features  \n20               [concave points error, worst radius]  \n0           [worst compactness, worst concave points]  \n22                  [mean area, worst concave points]  \n6                         [worst radius, mean radius]  \n27          [worst compactness, worst concave points]  \n29                      [mean concavity, mean radius]  \n5                     [worst texture, mean perimeter]  \n1                     [mean texture, worst concavity]  \n19                      [perimeter error, worst area]  \n24             [mean radius, worst fractal dimension]  \n3                      [mean concavity, radius error]  \n12                  [perimeter error, symmetry error]  \n11                    [texture error, mean perimeter]  \n14                  [mean smoothness, mean perimeter]  \n23                   [mean compactness, mean texture]  \n26         [worst concavity, fractal dimension error]  \n16                 [concavity error, perimeter error]  \n15                  [worst symmetry, perimeter error]  \n9                  [worst compactness, mean symmetry]  \n28                [worst smoothness, perimeter error]  \n18                [mean compactness, perimeter error]  \n4                   [concavity error, symmetry error]  \n25          [concave points error, worst compactness]  \n10                  [smoothness error, worst texture]  \n21           [smoothness error, concave points error]  \n7               [compactness error, worst smoothness]  \n13                  [symmetry error, concavity error]  \n2                 [compactness error, symmetry error]  \n8   [fractal dimension error, worst fractal dimens...  \n17          [symmetry error, fractal dimension error]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy train</th>\n      <th>accuracy test</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>0.925275</td>\n      <td>0.929825</td>\n      <td>[concave points error, worst radius]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.942857</td>\n      <td>0.903509</td>\n      <td>[worst compactness, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.934066</td>\n      <td>0.903509</td>\n      <td>[mean area, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.916484</td>\n      <td>0.894737</td>\n      <td>[worst radius, mean radius]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.931868</td>\n      <td>0.885965</td>\n      <td>[worst compactness, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.929670</td>\n      <td>0.877193</td>\n      <td>[mean concavity, mean radius]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.927473</td>\n      <td>0.868421</td>\n      <td>[worst texture, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.905495</td>\n      <td>0.850877</td>\n      <td>[mean texture, worst concavity]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.938462</td>\n      <td>0.842105</td>\n      <td>[perimeter error, worst area]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.903297</td>\n      <td>0.842105</td>\n      <td>[mean radius, worst fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.896703</td>\n      <td>0.833333</td>\n      <td>[mean concavity, radius error]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.841758</td>\n      <td>0.833333</td>\n      <td>[perimeter error, symmetry error]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.894505</td>\n      <td>0.824561</td>\n      <td>[texture error, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.909890</td>\n      <td>0.798246</td>\n      <td>[mean smoothness, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.841758</td>\n      <td>0.789474</td>\n      <td>[mean compactness, mean texture]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.892308</td>\n      <td>0.780702</td>\n      <td>[worst concavity, fractal dimension error]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.868132</td>\n      <td>0.780702</td>\n      <td>[concavity error, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.881319</td>\n      <td>0.771930</td>\n      <td>[worst symmetry, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.852747</td>\n      <td>0.771930</td>\n      <td>[worst compactness, mean symmetry]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.868132</td>\n      <td>0.754386</td>\n      <td>[worst smoothness, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.865934</td>\n      <td>0.754386</td>\n      <td>[mean compactness, perimeter error]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.817582</td>\n      <td>0.754386</td>\n      <td>[concavity error, symmetry error]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.824176</td>\n      <td>0.728070</td>\n      <td>[concave points error, worst compactness]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.778022</td>\n      <td>0.701754</td>\n      <td>[smoothness error, worst texture]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.813187</td>\n      <td>0.675439</td>\n      <td>[smoothness error, concave points error]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.786813</td>\n      <td>0.675439</td>\n      <td>[compactness error, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.804396</td>\n      <td>0.657895</td>\n      <td>[symmetry error, concavity error]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.778022</td>\n      <td>0.631579</td>\n      <td>[compactness error, symmetry error]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.784615</td>\n      <td>0.561404</td>\n      <td>[fractal dimension error, worst fractal dimens...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.734066</td>\n      <td>0.491228</td>\n      <td>[symmetry error, fractal dimension error]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fea_rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "with open('acc_fea_rank.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea_rank, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "81935aa1-c073-4eee-808d-20b60f0203da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Prześlij raport\n",
    "Prześlij plik o nazwie lab6.py realizujący ww. ćwiczenia.\n",
    "\n",
    "Sprawdzane będzie, czy skrypt Pythona tworzy wszystkie wymagane pliki oraz czy ich zawartość\n",
    "jest poprawna."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}