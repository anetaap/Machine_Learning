{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce497d-f4af-41a9-a5d6-7ee78ad88500",
   "metadata": {},
   "source": [
    "# 1. Cel / Zakres\n",
    "    - Metody zespołowe\n",
    "        - równoległe\n",
    "        - sekwencyjne\n",
    "    - Hard / soft voting\n",
    "    - Bagging\n",
    "    - Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522788e-11a0-41f2-a2c1-7ae226d841f1",
   "metadata": {},
   "source": [
    "# 2. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9adca48-7512-40a4-9fdb-bf124724aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c4070-ba9b-4ad5-8891-e93f3e35e2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Ćwiczenie:\n",
    "    - Uwaga: stosuj domyślne wartości parametrów dla użytych klas,\n",
    "      chyba, że z opisu danego ćwiczenia wynika inaczej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f7df4-3f9b-46ed-af08-46af71e88225",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Podział Zbioru\n",
    "Podziel zbiór data_breast_cancer na uczący i testujący w proporcjach 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d191c0d-c27c-4188-80a6-275d261fdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer = data_breast_cancer.data\n",
    "y_cancer = data_breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0d990d73-e0bb-4939-bcae-cf2409376fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Zbuduj ensemble\n",
    "Używając klasyfikatorów binarnych, których używałeś(aś) w poprzednich\n",
    "ćwiczeniach, tj.:\n",
    "\n",
    "    - drzewa decyzyjne,\n",
    "    - regresja logistyczna,\n",
    "    - k najbliższych sąsiadów,\n",
    "do klasyfikacji w oparciu o cechy:\n",
    "\n",
    "    - mean texture,\n",
    "    - mean symmetry.\n",
    "Użyj domyślnych parametrów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_cancer_train_texture_symmetry = X_cancer_train[[\"mean texture\", \"mean symmetry\"]]\n",
    "X_cancer_test_texture_symmetry = X_cancer_test[[\"mean texture\", \"mean symmetry\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=3)\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\")\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf_soft = VotingClassifier(\n",
    "        estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='soft'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8aee72ab-c736-4380-92cf-73686946d178",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Porównaj dokładność (accuracy)\n",
    "ww. klasyfikatorów z zespołem z głosowaniem typu:\n",
    "    \n",
    "    - hard\n",
    "    - soft."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('lr', LogisticRegression()),\n                             ('tr', DecisionTreeClassifier(max_depth=3)),\n                             ('knn', KNeighborsClassifier())],\n                 voting='soft')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "log_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "knn_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_hard.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_soft.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_train_tree_pred = tree_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_log_pred = log_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_knn_pred = knn_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vh_pred = voting_clf_hard.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vs_pred = voting_clf_soft.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "acc_tree_train = accuracy_score(y_cancer_train, y_train_tree_pred)\n",
    "acc_log_train = accuracy_score(y_cancer_train, y_train_log_pred)\n",
    "acc_knn_train = accuracy_score(y_cancer_train, y_train_knn_pred)\n",
    "acc_vh_train = accuracy_score(y_cancer_train, y_train_vh_pred)\n",
    "acc_vs_train = accuracy_score(y_cancer_train, y_train_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7692307692307693, 0.7230769230769231, 0.7714285714285715, 0.7802197802197802, 0.789010989010989]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_train, acc_log_train, acc_knn_train, acc_vh_train, acc_vs_train])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "y_test_tree_pred = tree_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_log_pred = log_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_knn_pred = knn_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vh_pred = voting_clf_hard.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vs_pred = voting_clf_soft.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "acc_tree_test = accuracy_score(y_cancer_test, y_test_tree_pred)\n",
    "acc_log_test = accuracy_score(y_cancer_test, y_test_log_pred)\n",
    "acc_knn_test = accuracy_score(y_cancer_test, y_test_knn_pred)\n",
    "acc_vh_test = accuracy_score(y_cancer_test, y_test_vh_pred)\n",
    "acc_vs_test = accuracy_score(y_cancer_test, y_test_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7368421052631579, 0.7017543859649122, 0.6403508771929824, 0.6754385964912281, 0.7456140350877193]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_test, acc_log_test, acc_knn_test, acc_vh_test, acc_vs_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "106bb175-57a5-4767-8d81-da0dc49cf5e2",
   "metadata": {},
   "source": [
    "#### 4. Zapisz rezultaty jako listę par\n",
    "    - (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z w/w klasyfikatorów i umieść ją w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_vote.pkl (razem 5 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - vote.pkl (5 obiektów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "accuracy =[(acc_tree_train, acc_tree_test),\n",
    "           (acc_log_train, acc_log_test),\n",
    "           (acc_knn_train, acc_log_test),\n",
    "           (acc_vh_train, acc_vh_test),\n",
    "           (acc_vs_train, acc_vs_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "clf = [tree_clf, log_clf, knn_clf, voting_clf_hard, voting_clf_soft]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3ca83de0-33a0-4542-b17a-555493c9eb7a",
   "metadata": {},
   "source": [
    "#### 5. Wykonaj na zbiorze uczącym \n",
    "    - wykorzystując 30 drzew decyzyjnych:\n",
    "- Bagging,\n",
    "- Bagging z wykorzystaniem 50% instancji,\n",
    "- Pasting,\n",
    "- Pasting z wykorzystaniem 50% instancji, oraz\n",
    "- Random Forest,\n",
    "- AdaBoost,\n",
    "- Gradient Boosting.\n",
    "\n",
    "###### - Dlaczego Random Forest daje inne rezultaty niż Bagging + drzewa decyzyjne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9d585e-80e6-4275-94c8-0fa44c33f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=True)\n",
    "\n",
    "bag_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                                 max_samples=0.5, bootstrap=True)\n",
    "\n",
    "pas_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=False)\n",
    "\n",
    "pas_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=False)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(max_depth=10)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "bag_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "rnd_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "ada_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "gb_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e9cdd9ea-7af6-4b94-b702-3151312191d2",
   "metadata": {},
   "source": [
    "#### 6. Oblicz dokładności oraz zapisz je jako listę par\n",
    "    -  (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z ww. estymatorów w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_bag.pkl (razem 7 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - bag.pkl (razem 7 elementów)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "y_train_b_pred = bag_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_bh_pred = bag_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_p_pred = pas_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_ph_pred = pas_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_r_pred = rnd_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_a_pred = ada_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_g_pred = gb_clf.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "acc_bag_train = accuracy_score(y_cancer_train, y_train_b_pred)\n",
    "acc_bagh_train = accuracy_score(y_cancer_train, y_train_bh_pred)\n",
    "acc_pas_train = accuracy_score(y_cancer_train, y_train_p_pred)\n",
    "acc_pash_train = accuracy_score(y_cancer_train, y_train_ph_pred)\n",
    "acc_rnd_train = accuracy_score(y_cancer_train, y_train_r_pred)\n",
    "acc_ada_train = accuracy_score(y_cancer_train, y_train_a_pred)\n",
    "acc_gb_train = accuracy_score(y_cancer_train, y_train_g_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "y_test_b_pred = bag_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_bh_pred = bag_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_p_pred = pas_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_ph_pred = pas_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_r_pred = rnd_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_a_pred = ada_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_g_pred = gb_clf.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a6e5964-eee4-410c-ae5e-661588c7eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_bag_test = accuracy_score(y_cancer_test, y_test_b_pred)\n",
    "acc_bagh_test = accuracy_score(y_cancer_test, y_test_bh_pred)\n",
    "acc_pas_test = accuracy_score(y_cancer_test, y_test_p_pred)\n",
    "acc_pash_test = accuracy_score(y_cancer_test, y_test_ph_pred)\n",
    "acc_rnd_test = accuracy_score(y_cancer_test, y_test_r_pred)\n",
    "acc_ada_test = accuracy_score(y_cancer_test, y_test_a_pred)\n",
    "acc_gb_test = accuracy_score(y_cancer_test, y_test_g_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "acc_bag = [(acc_bag_train, acc_bag_test),\n",
    "       (acc_bagh_train, acc_bagh_test),\n",
    "       (acc_pas_train, acc_pas_test),\n",
    "       (acc_pash_train, acc_pash_test),\n",
    "       (acc_rnd_train, acc_rnd_test),\n",
    "       (acc_ada_train, acc_ada_test),\n",
    "       (acc_gb_train, acc_gb_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open('acc_bag.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "bag = [bag_clf, bag_clf_half, pas_clf, pas_clf_half, rnd_clf, ada_clf, gb_clf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "10589a5a-b83b-4654-bb92-ac8d47bbcee9",
   "metadata": {},
   "source": [
    "#### 7. Przeprowadź sampling 2 cech z wszystkich dostepnych\n",
    "    - bez powtórzeń cech z wykorzystaniem 30 drzew decyzyjnych,\n",
    "    - wybierz połowę instancji dla każdego z drzew z powtórzeniami.\n",
    "    \n",
    "###### Notatka:\n",
    "###### Odnosnie zad 7: Tutaj BaggingClassifier z decision tree i max_features=2, Reszta ustawien domyslna trzeba uzyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "bag_clf_s = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=True, max_features=2, bootstrap_features=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n                  max_samples=0.5, n_estimators=30)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf_s.fit(X_cancer_train, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "y_train_bs_pred = bag_clf_s.predict(X_cancer_train)\n",
    "y_test_bs_pred = bag_clf_s.predict(X_cancer_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978021978021978 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "acc_bag_s_train = accuracy_score(y_cancer_train, y_train_bs_pred)\n",
    "acc_bag_s_test = accuracy_score(y_cancer_test, y_test_bs_pred)\n",
    "\n",
    "print(acc_bag_s_train, acc_bag_s_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Zapisz dokładności ww estymatora jako listę :\n",
    "    - dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego\n",
    "w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_fea.pkl.\n",
    "Zapisz klasyfikator jako jednoelementową listę w pliku Pickle o nazwie:\n",
    "\n",
    "    - fea.pkl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3526af87-c2b4-48e7-8d61-ddbe7a9cd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fea = [acc_bag_s_train, acc_bag_s_test]\n",
    "\n",
    "with open('acc_fea.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "fea = [bag_clf_s]\n",
    "\n",
    "with open('fea.pkl', 'wb') as f:\n",
    "    pickle.dump(fea, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2bfb34d1-ef87-44c3-b9fd-72976f174a71",
   "metadata": {},
   "source": [
    "#### 9. Sprawdź, które cechy dają najwięszą dokładność.\n",
    "Dostęp do poszczególnych estymatorów, aby obliczyć dokładność,\n",
    "możesz uzyskać za pmocą:\n",
    "    \n",
    "    - BaggingClasifier.estimators_.\n",
    "Cechy wybrane przez sampling dla każdego z estymatorów znajdziesz w:\n",
    "    \n",
    "    - BaggingClassifier.estimators_features_.\n",
    "    \n",
    "Zbuduj ranking estymatorów jako DataFrame, który będzie mieć w kolejnych kolumnach:\n",
    "    \n",
    "    - dokładność dla zb. uczącego,\n",
    "    - dokładnośc dla zb. testującego,\n",
    "    - lista nazw cech.\n",
    "    \n",
    "    - Każdy wiersz to informacje o jednym estymatorze.\n",
    "    - DataFrame posortuj malejąco po dokładności dla zbioru testującego i uczącego\n",
    "\n",
    "Zapisz w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_fea_rank.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dded99e7-ac9d-42e3-915c-f0a14f9afd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for estimator_, estimator_features_ in zip(bag_clf_s.estimators_, bag_clf_s.estimators_features_):\n",
    "    y_train_fea_pred = estimator_.predict(X_cancer_train.iloc[:, estimator_features_])\n",
    "    y_test_fea_pred = estimator_.predict(X_cancer_test.iloc[:, estimator_features_])\n",
    "\n",
    "    acc_fea_train = accuracy_score(y_cancer_train, y_train_fea_pred)\n",
    "    acc_fea_test = accuracy_score(y_cancer_test, y_test_fea_pred)\n",
    "\n",
    "    rank = [acc_fea_train, acc_fea_test, list(X_cancer.columns[estimator_features_])]\n",
    "\n",
    "    fea_rank.append(rank)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "acc_fea_rank = pd.DataFrame(fea_rank, columns=[\"accuracy train\", \"accuracy test\", \"features\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "acc_fea_rank.sort_values(by=\"accuracy test\", ascending=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "    accuracy train  accuracy test                                    features\n1         0.945055       0.956140             [worst radius, worst concavity]\n17        0.945055       0.956140            [worst smoothness, worst radius]\n22        0.927473       0.947368        [mean area, worst fractal dimension]\n15        0.914286       0.903509       [fractal dimension error, worst area]\n20        0.953846       0.903509            [worst texture, worst perimeter]\n28        0.907692       0.903509    [worst concave points, worst smoothness]\n9         0.918681       0.903509                  [mean texture, worst area]\n3         0.912088       0.894737                [worst symmetry, area error]\n14        0.949451       0.894737        [worst perimeter, compactness error]\n25        0.931868       0.885965         [mean radius, worst concave points]\n10        0.912088       0.877193      [mean concavity, worst concave points]\n26        0.920879       0.877193               [mean perimeter, mean radius]\n5         0.870330       0.868421       [area error, fractal dimension error]\n16        0.934066       0.868421      [concavity error, mean concave points]\n19        0.892308       0.859649             [mean radius, smoothness error]\n27        0.923077       0.850877     [mean concave points, worst smoothness]\n6         0.885714       0.850877       [fractal dimension error, area error]\n2         0.892308       0.850877               [mean perimeter, mean radius]\n18        0.896703       0.842105             [worst concavity, radius error]\n4         0.914286       0.842105             [mean perimeter, mean symmetry]\n24        0.874725       0.833333         [mean compactness, worst concavity]\n7         0.892308       0.824561             [texture error, mean concavity]\n0         0.929670       0.815789      [mean smoothness, mean concave points]\n11        0.837363       0.780702     [radius error, worst fractal dimension]\n29        0.780220       0.754386   [mean fractal dimension, concavity error]\n21        0.887912       0.736842          [mean concavity, worst smoothness]\n23        0.848352       0.710526             [radius error, mean smoothness]\n13        0.782418       0.684211      [mean fractal dimension, mean texture]\n12        0.784615       0.666667  [concavity error, fractal dimension error]\n8         0.852747       0.666667             [mean smoothness, radius error]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy train</th>\n      <th>accuracy test</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.945055</td>\n      <td>0.956140</td>\n      <td>[worst radius, worst concavity]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.945055</td>\n      <td>0.956140</td>\n      <td>[worst smoothness, worst radius]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.927473</td>\n      <td>0.947368</td>\n      <td>[mean area, worst fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.914286</td>\n      <td>0.903509</td>\n      <td>[fractal dimension error, worst area]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.953846</td>\n      <td>0.903509</td>\n      <td>[worst texture, worst perimeter]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.907692</td>\n      <td>0.903509</td>\n      <td>[worst concave points, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.918681</td>\n      <td>0.903509</td>\n      <td>[mean texture, worst area]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.912088</td>\n      <td>0.894737</td>\n      <td>[worst symmetry, area error]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.949451</td>\n      <td>0.894737</td>\n      <td>[worst perimeter, compactness error]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.931868</td>\n      <td>0.885965</td>\n      <td>[mean radius, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.912088</td>\n      <td>0.877193</td>\n      <td>[mean concavity, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.920879</td>\n      <td>0.877193</td>\n      <td>[mean perimeter, mean radius]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.870330</td>\n      <td>0.868421</td>\n      <td>[area error, fractal dimension error]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.934066</td>\n      <td>0.868421</td>\n      <td>[concavity error, mean concave points]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.892308</td>\n      <td>0.859649</td>\n      <td>[mean radius, smoothness error]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.923077</td>\n      <td>0.850877</td>\n      <td>[mean concave points, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.885714</td>\n      <td>0.850877</td>\n      <td>[fractal dimension error, area error]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.892308</td>\n      <td>0.850877</td>\n      <td>[mean perimeter, mean radius]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.896703</td>\n      <td>0.842105</td>\n      <td>[worst concavity, radius error]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.914286</td>\n      <td>0.842105</td>\n      <td>[mean perimeter, mean symmetry]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.874725</td>\n      <td>0.833333</td>\n      <td>[mean compactness, worst concavity]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.892308</td>\n      <td>0.824561</td>\n      <td>[texture error, mean concavity]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.929670</td>\n      <td>0.815789</td>\n      <td>[mean smoothness, mean concave points]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.837363</td>\n      <td>0.780702</td>\n      <td>[radius error, worst fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.780220</td>\n      <td>0.754386</td>\n      <td>[mean fractal dimension, concavity error]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.887912</td>\n      <td>0.736842</td>\n      <td>[mean concavity, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.848352</td>\n      <td>0.710526</td>\n      <td>[radius error, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.782418</td>\n      <td>0.684211</td>\n      <td>[mean fractal dimension, mean texture]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.784615</td>\n      <td>0.666667</td>\n      <td>[concavity error, fractal dimension error]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.852747</td>\n      <td>0.666667</td>\n      <td>[mean smoothness, radius error]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fea_rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "with open('acc_fea_rank.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea_rank, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "81935aa1-c073-4eee-808d-20b60f0203da",
   "metadata": {},
   "source": [
    "## 4. Prześlij raport\n",
    "Prześlij plik o nazwie lab6.py realizujący ww. ćwiczenia.\n",
    "\n",
    "Sprawdzane będzie, czy skrypt Pythona tworzy wszystkie wymagane pliki oraz czy ich zawartość\n",
    "jest poprawna."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}