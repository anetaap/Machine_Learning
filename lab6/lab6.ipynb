{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ce497d-f4af-41a9-a5d6-7ee78ad88500",
   "metadata": {},
   "source": [
    "# 1. Cel / Zakres\n",
    "    - Metody zespołowe\n",
    "        - równoległe\n",
    "        - sekwencyjne\n",
    "    - Hard / soft voting\n",
    "    - Bagging\n",
    "    - Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522788e-11a0-41f2-a2c1-7ae226d841f1",
   "metadata": {},
   "source": [
    "# 2. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9adca48-7512-40a4-9fdb-bf124724aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c4070-ba9b-4ad5-8891-e93f3e35e2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Ćwiczenie:\n",
    "    - Uwaga: stosuj domyślne wartości parametrów dla użytych klas,\n",
    "      chyba, że z opisu danego ćwiczenia wynika inaczej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f7df4-3f9b-46ed-af08-46af71e88225",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Podział Zbioru\n",
    "Podziel zbiór data_breast_cancer na uczący i testujący w proporcjach 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d191c0d-c27c-4188-80a6-275d261fdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer = data_breast_cancer.data\n",
    "y_cancer = data_breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0d990d73-e0bb-4939-bcae-cf2409376fef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Zbuduj ensemble\n",
    "Używając klasyfikatorów binarnych, których używałeś(aś) w poprzednich\n",
    "ćwiczeniach, tj.:\n",
    "\n",
    "    - drzewa decyzyjne,\n",
    "    - regresja logistyczna,\n",
    "    - k najbliższych sąsiadów,\n",
    "do klasyfikacji w oparciu o cechy:\n",
    "\n",
    "    - mean texture,\n",
    "    - mean symmetry.\n",
    "Użyj domyślnych parametrów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_cancer_train_texture_symmetry = X_cancer_train[[\"mean texture\", \"mean symmetry\"]]\n",
    "X_cancer_test_texture_symmetry = X_cancer_test[[\"mean texture\", \"mean symmetry\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=3)\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\")\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf_soft = VotingClassifier(\n",
    "        estimators=[('lr', log_clf),\n",
    "                ('tr', tree_clf),\n",
    "                ('knn', knn_clf)],\n",
    "    voting='soft'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8aee72ab-c736-4380-92cf-73686946d178",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Porównaj dokładność (accuracy)\n",
    "ww. klasyfikatorów z zespołem z głosowaniem typu:\n",
    "    \n",
    "    - hard\n",
    "    - soft."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('lr', LogisticRegression()),\n                             ('tr', DecisionTreeClassifier(max_depth=3)),\n                             ('knn', KNeighborsClassifier())],\n                 voting='soft')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "log_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "knn_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_hard.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "voting_clf_soft.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_train_tree_pred = tree_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_log_pred = log_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_knn_pred = knn_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vh_pred = voting_clf_hard.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_vs_pred = voting_clf_soft.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "acc_tree_train = accuracy_score(y_cancer_train, y_train_tree_pred)\n",
    "acc_log_train = accuracy_score(y_cancer_train, y_train_log_pred)\n",
    "acc_knn_train = accuracy_score(y_cancer_train, y_train_knn_pred)\n",
    "acc_vh_train = accuracy_score(y_cancer_train, y_train_vh_pred)\n",
    "acc_vs_train = accuracy_score(y_cancer_train, y_train_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7692307692307693, 0.7230769230769231, 0.7714285714285715, 0.7802197802197802, 0.789010989010989]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_train, acc_log_train, acc_knn_train, acc_vh_train, acc_vs_train])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "y_test_tree_pred = tree_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_log_pred = log_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_knn_pred = knn_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vh_pred = voting_clf_hard.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_vs_pred = voting_clf_soft.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "acc_tree_test = accuracy_score(y_cancer_test, y_test_tree_pred)\n",
    "acc_log_test = accuracy_score(y_cancer_test, y_test_log_pred)\n",
    "acc_knn_test = accuracy_score(y_cancer_test, y_test_knn_pred)\n",
    "acc_vh_test = accuracy_score(y_cancer_test, y_test_vh_pred)\n",
    "acc_vs_test = accuracy_score(y_cancer_test, y_test_vs_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7368421052631579, 0.7017543859649122, 0.6403508771929824, 0.6754385964912281, 0.7456140350877193]\n"
     ]
    }
   ],
   "source": [
    "print([acc_tree_test, acc_log_test, acc_knn_test, acc_vh_test, acc_vs_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "106bb175-57a5-4767-8d81-da0dc49cf5e2",
   "metadata": {},
   "source": [
    "#### 4. Zapisz rezultaty jako listę par\n",
    "    - (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z w/w klasyfikatorów i umieść ją w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_vote.pkl (razem 5 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - vote.pkl (5 obiektów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "accuracy =[(acc_tree_train, acc_tree_test),\n",
    "           (acc_log_train, acc_log_test),\n",
    "           (acc_knn_train, acc_log_test),\n",
    "           (acc_vh_train, acc_vh_test),\n",
    "           (acc_vs_train, acc_vs_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "clf = [tree_clf, log_clf, knn_clf, voting_clf_hard, voting_clf_soft]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3ca83de0-33a0-4542-b17a-555493c9eb7a",
   "metadata": {},
   "source": [
    "#### 5. Wykonaj na zbiorze uczącym \n",
    "    - wykorzystując 30 drzew decyzyjnych:\n",
    "- Bagging,\n",
    "- Bagging z wykorzystaniem 50% instancji,\n",
    "- Pasting,\n",
    "- Pasting z wykorzystaniem 50% instancji, oraz\n",
    "- Random Forest,\n",
    "- AdaBoost,\n",
    "- Gradient Boosting.\n",
    "\n",
    "###### - Dlaczego Random Forest daje inne rezultaty niż Bagging + drzewa decyzyjne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9d585e-80e6-4275-94c8-0fa44c33f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=True)\n",
    "\n",
    "bag_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                                 max_samples=0.5, bootstrap=True)\n",
    "\n",
    "pas_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=1.0, bootstrap=False)\n",
    "\n",
    "pas_clf_half = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=False)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=30)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=30)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "bag_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "pas_clf_half.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "rnd_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "ada_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)\n",
    "gb_clf.fit(X_cancer_train_texture_symmetry, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e9cdd9ea-7af6-4b94-b702-3151312191d2",
   "metadata": {},
   "source": [
    "#### 6. Oblicz dokładności oraz zapisz je jako listę par\n",
    "    -  (dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego)\n",
    "dla każdego z ww. estymatorów w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_bag.pkl (razem 7 elementów)\n",
    "Zapisz klasyfikatory jako listę w pliku Pickle o nazwie:\n",
    "    \n",
    "    - bag.pkl (razem 7 elementów)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TRAIN SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "y_train_b_pred = bag_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_bh_pred = bag_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_p_pred = pas_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_ph_pred = pas_clf_half.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_r_pred = rnd_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_a_pred = ada_clf.predict(X_cancer_train_texture_symmetry)\n",
    "y_train_g_pred = gb_clf.predict(X_cancer_train_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "acc_bag_train = accuracy_score(y_cancer_train, y_train_b_pred)\n",
    "acc_bagh_train = accuracy_score(y_cancer_train, y_train_bh_pred)\n",
    "acc_pas_train = accuracy_score(y_cancer_train, y_train_p_pred)\n",
    "acc_pash_train = accuracy_score(y_cancer_train, y_train_ph_pred)\n",
    "acc_rnd_train = accuracy_score(y_cancer_train, y_train_r_pred)\n",
    "acc_ada_train = accuracy_score(y_cancer_train, y_train_a_pred)\n",
    "acc_gb_train = accuracy_score(y_cancer_train, y_train_g_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***TEST SET***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "y_test_b_pred = bag_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_bh_pred = bag_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_p_pred = pas_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_ph_pred = pas_clf_half.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_r_pred = rnd_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_a_pred = ada_clf.predict(X_cancer_test_texture_symmetry)\n",
    "y_test_g_pred = gb_clf.predict(X_cancer_test_texture_symmetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a6e5964-eee4-410c-ae5e-661588c7eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_bag_test = accuracy_score(y_cancer_test, y_test_b_pred)\n",
    "acc_bagh_test = accuracy_score(y_cancer_test, y_test_bh_pred)\n",
    "acc_pas_test = accuracy_score(y_cancer_test, y_test_p_pred)\n",
    "acc_pash_test = accuracy_score(y_cancer_test, y_test_ph_pred)\n",
    "acc_rnd_test = accuracy_score(y_cancer_test, y_test_r_pred)\n",
    "acc_ada_test = accuracy_score(y_cancer_test, y_test_a_pred)\n",
    "acc_gb_test = accuracy_score(y_cancer_test, y_test_g_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "acc_bag = [(acc_bag_train, acc_bag_test),\n",
    "       (acc_bagh_train, acc_bagh_test),\n",
    "       (acc_pas_train, acc_pas_test),\n",
    "       (acc_pash_train, acc_pash_test),\n",
    "       (acc_rnd_train, acc_rnd_test),\n",
    "       (acc_ada_train, acc_ada_test),\n",
    "       (acc_gb_train, acc_gb_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open('acc_bag.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "bag = [bag_clf, bag_clf_half, pas_clf, pas_clf_half, rnd_clf, ada_clf, gb_clf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "10589a5a-b83b-4654-bb92-ac8d47bbcee9",
   "metadata": {},
   "source": [
    "#### 7. Przeprowadź sampling 2 cech z wszystkich dostepnych\n",
    "    - bez powtórzeń cech z wykorzystaniem 30 drzew decyzyjnych,\n",
    "    - wybierz połowę instancji dla każdego z drzew z powtórzeniami.\n",
    "    \n",
    "###### Notatka:\n",
    "###### Odnosnie zad 7: Tutaj BaggingClassifier z decision tree i max_features=2, Reszta ustawien domyslna trzeba uzyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "bag_clf_s = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30,\n",
    "                            max_samples=0.5, bootstrap=True, max_features=2, bootstrap_features=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n                  max_samples=0.5, n_estimators=30)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf_s.fit(X_cancer_train, y_cancer_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "y_train_bs_pred = bag_clf_s.predict(X_cancer_train)\n",
    "y_test_bs_pred = bag_clf_s.predict(X_cancer_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "acc_bag_s_train = accuracy_score(y_cancer_train, y_train_bs_pred)\n",
    "acc_bag_s_test = accuracy_score(y_cancer_test, y_test_bs_pred)\n",
    "\n",
    "print(acc_bag_s_train, acc_bag_s_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8. Zapisz dokładności ww estymatora jako listę :\n",
    "    - dokładność_dla_zb_uczącego, dokładność_dla_zb_testującego\n",
    "w pliku Pickle o nazwie:\n",
    "\n",
    "    - acc_fea.pkl.\n",
    "Zapisz klasyfikator jako jednoelementową listę w pliku Pickle o nazwie:\n",
    "\n",
    "    - fea.pkl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3526af87-c2b4-48e7-8d61-ddbe7a9cd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fea = [acc_bag_s_train, acc_bag_s_test]\n",
    "\n",
    "with open('acc_fea.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "fea = [bag_clf_s]\n",
    "\n",
    "with open('fea.pkl', 'wb') as f:\n",
    "    pickle.dump(fea, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2bfb34d1-ef87-44c3-b9fd-72976f174a71",
   "metadata": {},
   "source": [
    "#### 9. Sprawdź, które cechy dają najwięszą dokładność.\n",
    "Dostęp do poszczególnych estymatorów, aby obliczyć dokładność,\n",
    "możesz uzyskać za pmocą:\n",
    "    \n",
    "    - BaggingClasifier.estimators_.\n",
    "Cechy wybrane przez sampling dla każdego z estymatorów znajdziesz w:\n",
    "    \n",
    "    - BaggingClassifier.estimators_features_.\n",
    "    \n",
    "Zbuduj ranking estymatorów jako DataFrame, który będzie mieć w kolejnych kolumnach:\n",
    "    \n",
    "    - dokładność dla zb. uczącego,\n",
    "    - dokładnośc dla zb. testującego,\n",
    "    - lista nazw cech.\n",
    "    \n",
    "    - Każdy wiersz to informacje o jednym estymatorze.\n",
    "    - DataFrame posortuj malejąco po dokładności dla zbioru testującego i uczącego\n",
    "\n",
    "Zapisz w pliku Pickle o nazwie:\n",
    "    \n",
    "    - acc_fea_rank.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dded99e7-ac9d-42e3-915c-f0a14f9afd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\aneta_p\\documents\\studia\\semestr_4\\machine_learning\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for estimator_, estimator_features_ in zip(bag_clf_s.estimators_, bag_clf_s.estimators_features_):\n",
    "    y_train_fea_pred = estimator_.predict(X_cancer_train.iloc[:, estimator_features_])\n",
    "    y_test_fea_pred = estimator_.predict(X_cancer_test.iloc[:, estimator_features_])\n",
    "\n",
    "    acc_fea_train = accuracy_score(y_cancer_train, y_train_fea_pred)\n",
    "    acc_fea_test = accuracy_score(y_cancer_test, y_test_fea_pred)\n",
    "\n",
    "    rank = [acc_fea_train, acc_fea_test, list(X_cancer.columns[estimator_features_])]\n",
    "\n",
    "    fea_rank.append(rank)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "acc_fea_rank = pd.DataFrame(fea_rank, columns=[\"accuracy train\", \"accuracy test\", \"features\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "acc_fea_rank.sort_values(by=\"accuracy test\", ascending=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "    accuracy train  accuracy test                                    features\n17        0.942857       0.929825         [smoothness error, worst perimeter]\n16        0.938462       0.929825             [worst compactness, worst area]\n7         0.929670       0.929825                  [worst area, worst radius]\n29        0.914286       0.912281       [worst texture, worst concave points]\n10        0.925275       0.912281              [worst compactness, mean area]\n9         0.947253       0.903509               [worst smoothness, mean area]\n25        0.887912       0.903509                     [area error, mean area]\n27        0.936264       0.877193                 [worst radius, mean radius]\n19        0.887912       0.877193              [perimeter error, mean radius]\n15        0.927473       0.877193                 [worst area, texture error]\n6         0.909890       0.877193           [compactness error, worst radius]\n5         0.894505       0.877193              [radius error, mean perimeter]\n3         0.896703       0.877193        [mean concave points, mean symmetry]\n22        0.905495       0.859649                  [mean symmetry, mean area]\n14        0.861538       0.859649               [area error, mean smoothness]\n23        0.907692       0.859649                [mean radius, texture error]\n28        0.881319       0.842105                [mean area, concavity error]\n21        0.868132       0.833333            [worst concavity, mean symmetry]\n8         0.861538       0.798246          [area error, concave points error]\n12        0.870330       0.771930         [mean compactness, worst concavity]\n24        0.804396       0.763158     [concave points error, concavity error]\n2         0.850549       0.736842            [worst smoothness, radius error]\n20        0.775824       0.675439        [compactness error, concavity error]\n26        0.795604       0.666667     [mean texture, worst fractal dimension]\n18        0.780220       0.657895      [mean texture, mean fractal dimension]\n13        0.723077       0.657895       [mean symmetry, concave points error]\n0         0.797802       0.614035         [worst smoothness, mean smoothness]\n4         0.804396       0.605263           [mean symmetry, worst smoothness]\n1         0.751648       0.587719  [mean smoothness, fractal dimension error]\n11        0.742857       0.543860  [mean smoothness, worst fractal dimension]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy train</th>\n      <th>accuracy test</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>0.942857</td>\n      <td>0.929825</td>\n      <td>[smoothness error, worst perimeter]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.938462</td>\n      <td>0.929825</td>\n      <td>[worst compactness, worst area]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.929670</td>\n      <td>0.929825</td>\n      <td>[worst area, worst radius]</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.914286</td>\n      <td>0.912281</td>\n      <td>[worst texture, worst concave points]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.925275</td>\n      <td>0.912281</td>\n      <td>[worst compactness, mean area]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.947253</td>\n      <td>0.903509</td>\n      <td>[worst smoothness, mean area]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.887912</td>\n      <td>0.903509</td>\n      <td>[area error, mean area]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.936264</td>\n      <td>0.877193</td>\n      <td>[worst radius, mean radius]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.887912</td>\n      <td>0.877193</td>\n      <td>[perimeter error, mean radius]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.927473</td>\n      <td>0.877193</td>\n      <td>[worst area, texture error]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.909890</td>\n      <td>0.877193</td>\n      <td>[compactness error, worst radius]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.894505</td>\n      <td>0.877193</td>\n      <td>[radius error, mean perimeter]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.896703</td>\n      <td>0.877193</td>\n      <td>[mean concave points, mean symmetry]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.905495</td>\n      <td>0.859649</td>\n      <td>[mean symmetry, mean area]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.861538</td>\n      <td>0.859649</td>\n      <td>[area error, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.907692</td>\n      <td>0.859649</td>\n      <td>[mean radius, texture error]</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.881319</td>\n      <td>0.842105</td>\n      <td>[mean area, concavity error]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.868132</td>\n      <td>0.833333</td>\n      <td>[worst concavity, mean symmetry]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.861538</td>\n      <td>0.798246</td>\n      <td>[area error, concave points error]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.870330</td>\n      <td>0.771930</td>\n      <td>[mean compactness, worst concavity]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.804396</td>\n      <td>0.763158</td>\n      <td>[concave points error, concavity error]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.850549</td>\n      <td>0.736842</td>\n      <td>[worst smoothness, radius error]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.775824</td>\n      <td>0.675439</td>\n      <td>[compactness error, concavity error]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.795604</td>\n      <td>0.666667</td>\n      <td>[mean texture, worst fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.780220</td>\n      <td>0.657895</td>\n      <td>[mean texture, mean fractal dimension]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.723077</td>\n      <td>0.657895</td>\n      <td>[mean symmetry, concave points error]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.797802</td>\n      <td>0.614035</td>\n      <td>[worst smoothness, mean smoothness]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.804396</td>\n      <td>0.605263</td>\n      <td>[mean symmetry, worst smoothness]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.751648</td>\n      <td>0.587719</td>\n      <td>[mean smoothness, fractal dimension error]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.742857</td>\n      <td>0.543860</td>\n      <td>[mean smoothness, worst fractal dimension]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fea_rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "with open('acc_fea_rank.pkl', 'wb') as f:\n",
    "    pickle.dump(acc_fea_rank, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "81935aa1-c073-4eee-808d-20b60f0203da",
   "metadata": {},
   "source": [
    "## 4. Prześlij raport\n",
    "Prześlij plik o nazwie lab6.py realizujący ww. ćwiczenia.\n",
    "\n",
    "Sprawdzane będzie, czy skrypt Pythona tworzy wszystkie wymagane pliki oraz czy ich zawartość\n",
    "jest poprawna."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}